{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U kaleido"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tunZTNkXHcH8",
        "outputId": "ad80bd3d-822b-4713-c534-8247a2fbf822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaleido in /usr/local/lib/python3.10/dist-packages (0.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easyocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-6IuXw_LZYu",
        "outputId": "580c3ba8-5f94-4d85-a264-08d34cbef06e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting easyocr\n",
            "  Downloading easyocr-1.7.1-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.18.0+cu121)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.10.0.84)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.11.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (9.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.19.3)\n",
            "Collecting python-bidi (from easyocr)\n",
            "  Downloading python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.4)\n",
            "Collecting pyclipper (from easyocr)\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from easyocr)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->easyocr)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->easyocr)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->easyocr)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->easyocr)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->easyocr)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->easyocr)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->easyocr)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->easyocr)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->easyocr)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->easyocr)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->easyocr)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->easyocr)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from python-bidi->easyocr) (1.16.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2024.7.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (24.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easyocr) (1.3.0)\n",
            "Installing collected packages: pyclipper, ninja, python-bidi, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, easyocr\n",
            "Successfully installed easyocr-1.7.1 ninja-1.11.1.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 pyclipper-1.3.0.post5 python-bidi-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "KUg-SEBKL5YH",
        "outputId": "8b7b1244-3b27-465d-9cae-2284aedb531f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n",
            "100%|██████████| 160M/160M [00:02<00:00, 68.6MB/s]\n",
            "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/Dataset/Untitled spreadsheet - Sheet1.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d14271282ebd>\u001b[0m in \u001b[0;36m<cell line: 139>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0mfocal_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000.0\u001b[0m  \u001b[0;31m# Adjust as per your camera setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0moutput_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/Dataset/Untitled spreadsheet - Sheet1.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m \u001b[0mprocess_realtime_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfocal_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-d14271282ebd>\u001b[0m in \u001b[0;36mprocess_realtime_video\u001b[0;34m(video_path, focal_length, output_csv)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0;31m# Open CSV file for writing license plate predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m       \u001b[0mfieldnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Frame'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'License Plate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Confidence Score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'X'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Speed (km/h)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m       \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfieldnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfieldnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/Dataset/Untitled spreadsheet - Sheet1.csv'"
          ]
        }
      ],
      "source": [
        "  #!pip install easyocr\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "import csv\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "import torchvision.transforms as T\n",
        "import easyocr\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load the pre-trained Faster R-CNN model\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Set device to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Define a transformation for the input image\n",
        "transform = T.Compose([T.ToTensor()])\n",
        "\n",
        "# Initialize EasyOCR for license plate OCR\n",
        "reader = easyocr.Reader(['en'], gpu=True)\n",
        "\n",
        "# Function to perform object detection and classification\n",
        "def detect_objects(image):\n",
        "    input_tensor = transform(image).to(device)\n",
        "    input_batch = input_tensor.unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predictions = model(input_batch)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Function to calculate the absolute speed of a vehicle\n",
        "def calculate_absolute_speed(prev_position, current_position, time_diff, focal_length):\n",
        "    distance_pixels = np.linalg.norm(current_position - prev_position)\n",
        "    distance_meters = (focal_length * 2) / distance_pixels\n",
        "    speed_mps = distance_meters / time_diff\n",
        "    speed_kph = speed_mps * 3.6\n",
        "    return speed_kph\n",
        "\n",
        "# Function to perform OCR on license plates\n",
        "def ocr_license_plate(image, coordinates):\n",
        "    x, y, w, h = int(coordinates[0]), int(coordinates[1]), int(coordinates[2]), int(coordinates[3])\n",
        "    plate_image = image[y:h, x:w]\n",
        "\n",
        "    gray_plate = cv2.cvtColor(plate_image, cv2.COLOR_RGB2GRAY)\n",
        "    result = reader.readtext(gray_plate, detail=0)\n",
        "    license_plate_number = \"\"\n",
        "    confidence_score = 0.0\n",
        "\n",
        "    for res in result:\n",
        "\n",
        "        if len(res) > 6:\n",
        "            license_plate_number = res\n",
        "\n",
        "\n",
        "    return license_plate_number, confidence_score\n",
        "\n",
        "# Function to process video frames and write results to CSV\n",
        "def process_frame(frame, prev_positions, prev_time, writer, video_capture, focal_length):\n",
        "    predictions = detect_objects(frame)\n",
        "\n",
        "    boxes = predictions[0]['boxes'].cpu().numpy()\n",
        "    labels = predictions[0]['labels'].cpu().numpy()\n",
        "\n",
        "    current_time = time.time()\n",
        "    time_diff = current_time - prev_time\n",
        "\n",
        "    for box, label in zip(boxes, labels):\n",
        "        box_center = np.array([(box[0] + box[2]) / 2, (box[1] + box[3]) / 2])\n",
        "        if label in prev_positions:\n",
        "            prev_position = prev_positions[label]\n",
        "            speed = calculate_absolute_speed(prev_position, box_center, time_diff, focal_length)\n",
        "\n",
        "            license_plate_number, confidence_score = ocr_license_plate(frame, box)\n",
        "\n",
        "            # Write license plate number and confidence level to CSV\n",
        "            if license_plate_number:\n",
        "                writer.writerow({'Frame': int(video_capture.get(cv2.CAP_PROP_POS_FRAMES)),\n",
        "                                 'Label': label,\n",
        "                                 'License Plate': license_plate_number,\n",
        "                                 'Confidence Score': confidence_score,\n",
        "                                 'X': box_center[0],\n",
        "                                 'Y': box_center[1],\n",
        "                                 'Speed (km/h)': speed})\n",
        "\n",
        "                # Draw bounding box around the detected object\n",
        "                cv2.rectangle(frame, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 255, 0), 2)\n",
        "\n",
        "                # Display the license plate number and speed on the frame\n",
        "                text = f'{license_plate_number} {speed:.2f} km/h'\n",
        "                cv2.putText(frame, text, (int(box[0]), int(box[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "        prev_positions[label] = box_center\n",
        "\n",
        "    return frame\n",
        "\n",
        "# Function to process real-time video stream\n",
        "def process_realtime_video(video_path, focal_length, output_csv):\n",
        "    video_capture = cv2.VideoCapture(video_path)\n",
        "    prev_positions = {}\n",
        "    prev_time = time.time()\n",
        "\n",
        "    # Get video frame properties\n",
        "    frame_width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    # Open CSV file for writing license plate predictions\n",
        "    with open(output_csv, 'w', newline='') as csvfile:\n",
        "        fieldnames = ['Frame', 'Label', 'License Plate', 'Confidence Score', 'X', 'Y', 'Speed (km/h)']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        while True:\n",
        "            ret, frame = video_capture.read()\n",
        "\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            processed_frame = process_frame(frame, prev_positions, prev_time, writer, video_capture, focal_length)\n",
        "\n",
        "            cv2_imshow(processed_frame)\n",
        "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                break\n",
        "\n",
        "            prev_time = time.time()\n",
        "\n",
        "    video_capture.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Run the real-time video processing function\n",
        "video_path = '/content/drive/MyDrive/Colab Notebooks/Dataset/pexels_videos_2103099 (2160p) (1) (online-video-cutter.com).mp4'\n",
        "focal_length = 1000.0  # Adjust as per your camera setup\n",
        "output_csv = '/content/drive/MyDrive/Colab Notebooks/Dataset/Untitled spreadsheet - Sheet1.csv'\n",
        "process_realtime_video(video_path, focal_length, output_csv)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jYqBouxWrNMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6iwbf5_GpPi"
      },
      "source": [
        "Object Motion detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fbx9w8xZ_XMS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import cv2\n",
        "import numpy as np\n",
        "from torchvision.transforms import functional as F\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "# Define the class labels for Faster R-CNN\n",
        "faster_rcnn_classes = [\n",
        "    'background', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
        "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag',\n",
        "    'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite',\n",
        "    'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "    'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana',\n",
        "    'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table',\n",
        "    'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
        "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock',\n",
        "    'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]\n",
        "\n",
        "# Load the pre-trained Faster R-CNN model\n",
        "fasterrcnn_model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "fasterrcnn_model.eval()\n",
        "\n",
        "# Function to perform inference using Faster R-CNN\n",
        "def detect_objects_fasterrcnn(frame, model):\n",
        "    image = Image.fromarray(frame)\n",
        "    image_tensor = F.to_tensor(image)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model([image_tensor])\n",
        "\n",
        "    return outputs[0]\n",
        "\n",
        "# Function to draw bounding boxes and labels\n",
        "def draw_boxes(frame, detections, classes):\n",
        "    for box, label, score in zip(detections['boxes'], detections['labels'], detections['scores']):\n",
        "        if score > 0.5:\n",
        "            x1, y1, x2, y2 = map(int, box.tolist())\n",
        "            label = f'{classes[label.item()]}: {score:.2f}'\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "    return frame\n",
        "\n",
        "# Open the video file\n",
        "video_path = '/content/drive/MyDrive/Colab Notebooks/Dataset/Video.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Prepare for saving output video\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "out = cv2.VideoWriter('output.avi', fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Perform inference using Faster R-CNN\n",
        "    detections_fasterrcnn = detect_objects_fasterrcnn(frame, fasterrcnn_model)\n",
        "\n",
        "    # Draw bounding boxes and labels\n",
        "    frame_fasterrcnn = draw_boxes(frame.copy(), detections_fasterrcnn, faster_rcnn_classes)\n",
        "\n",
        "    # Write the frame with detections to the output video\n",
        "    out.write(frame_fasterrcnn)\n",
        "\n",
        "    # Display the frame\n",
        "    cv2_imshow(frame_fasterrcnn)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release video capture and writer objects\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ugWdV_vG4zQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "642815bb-91c2-40b8-9f44-3a1dfaf61c72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 1s (6,171 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 123576 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "!pip install pytesseract\n",
        "!apt-get install tesseract-ocr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06J7Mf5AHaFN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8bfd2379-017a-4603-8b06-683be80f4a20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: easyocr in /usr/local/lib/python3.10/dist-packages (1.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.18.0+cu121)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.10.0.84)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.11.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (9.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.19.3)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.4.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.4)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.3.0.post5)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.11.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->easyocr) (12.5.82)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from python-bidi->easyocr) (1.16.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2024.7.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (24.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easyocr) (1.3.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-7c82e38a7059>\u001b[0m in \u001b[0;36m<cell line: 147>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;31m# Perform OCR using Tesseract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mtesseract_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mocr_tesseract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0mtesseract_texts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesseract_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-7c82e38a7059>\u001b[0m in \u001b[0;36mocr_tesseract\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Function to perform OCR using Tesseract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mocr_tesseract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ],
      "source": [
        "import pytesseract\n",
        "!pip install easyocr\n",
        "import easyocr\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import re\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "# Initialize EasyOCR reader\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "# Function to perform OCR using Tesseract\n",
        "def ocr_tesseract(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    text = pytesseract.image_to_string(gray).strip()\n",
        "    return text\n",
        "\n",
        "# Function to perform OCR using EasyOCR\n",
        "def ocr_easyocr(image):\n",
        "    result = reader.readtext(image)\n",
        "    text = ' '.join([res[1] for res in result])\n",
        "    return text\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    # Remove extra whitespace, newlines, and non-alphanumeric characters\n",
        "    text = text.strip()\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    return text.lower()\n",
        "\n",
        "# Function to calculate similarity ratio\n",
        "def calculate_similarity(gt_text, pred_text):\n",
        "    return SequenceMatcher(None, gt_text, pred_text).ratio()\n",
        "\n",
        "# Function to calculate accuracy\n",
        "def calculate_accuracy(gt_texts, pred_texts):\n",
        "    correct = sum([1 for gt, pred in zip(gt_texts, pred_texts) if gt == pred])\n",
        "    return correct / len(gt_texts)\n",
        "\n",
        "# Sample images and ground truth texts\n",
        "image_paths = [\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/WB1.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/WB11.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/WB12.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/WB13.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/WB14.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/WB15.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/WB16.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/WB17.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/WB18.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/WB19.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/WB20.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/WB21.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/WB22.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/WB23.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/WB25.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/WB26.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/WB27.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/WB28.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/WB2.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/WB3.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/WB4.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/WB5.jpg',\n",
        "      '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/WB6.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/WB8.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/WB9.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/DN1.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/DN2.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/DN3.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/DN4.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/DN5.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/DN6.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/DN7.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/DN8.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/RJ2.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/RJ4.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/RJ5.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/RJ6.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/RJ7.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/RJ9.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/RJ10.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/TN1.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/TN2.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/TN3.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/TN4.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/TN5.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/TN6.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/TN7.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/TN8.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/TN9.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/TN10.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/UP1.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/UP2.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/UP3.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/UP4.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/UP5.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/UP8.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/UP10.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/UP11.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/UP12.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/UP14.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/UP15.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/UP16.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/UP17.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/UP19.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/UP20.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/UP21.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/UP22.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/UP23.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/UP24.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/UP25.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/UP26.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/UP27.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/UP28.jpg',\n",
        "     '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/UP29.jpg'\n",
        "\n",
        "]\n",
        "gt_texts = [\n",
        "    'WB26T6688','WB08A4101','WB26S5093',\n",
        "    'WB26K2760','WB36G6682',\n",
        "    'WB12AX2987','WB06J9177','WB02AJ4534',\n",
        "    'WB06J2192','WB061061','WB171717',\n",
        "    'WB02W9S3S','WB20H0271','WB20AG9041',\n",
        "    'WB06H2237','WB02A03017','WB02AD4162',\n",
        "    'WB02AM8548','WB02M8447','WB70G3763','WB02X8795',\n",
        "    'WB06G4120','WB02AH4655','WB06J4432','WB02AA5580',\n",
        "    'DN09H2191','DN09J0548','DN09H0968','DN09J0032','DN09D2724',\n",
        "    'DN0901438','DN0909704','DN09C0868',\n",
        "    'RJ14CW4115','RJ20CD5118','RJ14CF5807','RJ23CB2272',\n",
        "    'RJ23CB4320','RJ20UB0137','RJ14CM3730',\n",
        "    'TN63BV7954','TN76V1978','TN02AU9295','TN10AR0131',\n",
        "    'TN47T4464','TN19F0816','TN07BT5778','TN07AP0659','TN19Q0835','TN69AJ4455',\n",
        "    'UP57H8173','UP85BN4203','UP80FA1666','UP16U3849','UP32EC5577','UP16AJ0704','UP78DB3730',\n",
        "    'UP53AK1161','UP14CV7920','UP16BD4866','UP79L0567','UP32KW7325','UP32CX3400','UP45Q3028',\n",
        "    'UP14AK8604','UP52AH9705','UP11AY0646','UP78ED0449','UP27Z7322','UP32BF3577','UP14AX9754',\n",
        "    'UP70ET7816','UP32HY6077','UP14AF3804'\n",
        "    # Add corresponding ground truth texts\n",
        "]\n",
        "\n",
        "tesseract_texts = []\n",
        "easyocr_texts = []\n",
        "tesseract_accuracies = []\n",
        "easyocr_accuracies = []\n",
        "for image_path,gt_text in zip(image_paths,gt_texts):\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Perform OCR using Tesseract\n",
        "    tesseract_text = ocr_tesseract(image)\n",
        "    tesseract_texts.append(tesseract_text)\n",
        "\n",
        "    # Perform OCR using EasyOCR\n",
        "    easyocr_text = ocr_easyocr(image)\n",
        "    easyocr_texts.append(easyocr_text)\n",
        "     # Preprocess texts\n",
        "    gt_text_clean = preprocess_text(gt_text)\n",
        "    tesseract_text_clean = preprocess_text(tesseract_text)\n",
        "    easyocr_text_clean = preprocess_text(easyocr_text)\n",
        "\n",
        "    # Calculate similarity ratios\n",
        "    tesseract_similarity = calculate_similarity(gt_text_clean, tesseract_text_clean)\n",
        "    easyocr_similarity = calculate_similarity(gt_text_clean, easyocr_text_clean)\n",
        "\n",
        "    # Append accuracies (similarity ratios)\n",
        "    tesseract_accuracies.append(tesseract_similarity)\n",
        "    easyocr_accuracies.append(easyocr_similarity)\n",
        "\n",
        "# Calculate average accuracies\n",
        "average_tesseract_accuracy = np.mean(tesseract_accuracies)\n",
        "average_easyocr_accuracy = np.mean(easyocr_accuracies)\n",
        "\n",
        "print(\"Tesseract OCR Accuracy:\", average_tesseract_accuracy * 100)\n",
        "print(\"EasyOCR Accuracy:\", average_easyocr_accuracy * 100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAJqxJZ-bFTf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load a pre-trained Faster R-CNN model\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Define COCO class names (first class is the background)\n",
        "COCO_INSTANCE_CATEGORY_NAMES = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter',\n",
        "    'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra',\n",
        "    'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis',\n",
        "    'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "    'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon',\n",
        "    'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet',\n",
        "    'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
        "    'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
        "    'toothbrush'\n",
        "]\n",
        "\n",
        "# Define the image transformation\n",
        "transform = T.Compose([\n",
        "    T.ToTensor()\n",
        "])\n",
        "\n",
        "# Load the image\n",
        "image_path = '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/Classification.jpg'\n",
        "image = Image.open(image_path)\n",
        "image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    predictions = model(image_tensor)\n",
        "\n",
        "# Get the predictions\n",
        "pred_boxes = predictions[0]['boxes'].cpu().numpy()\n",
        "pred_scores = predictions[0]['scores'].cpu().numpy()\n",
        "pred_classes = predictions[0]['labels'].cpu().numpy()\n",
        "\n",
        "# Filter out low confidence scores\n",
        "threshold = 0.5\n",
        "filtered_boxes = pred_boxes[pred_scores >= threshold]\n",
        "filtered_classes = pred_classes[pred_scores >= threshold]\n",
        "\n",
        "# Draw bounding boxes on the original image\n",
        "output_image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "for i, box in enumerate(filtered_boxes):\n",
        "    if COCO_INSTANCE_CATEGORY_NAMES[filtered_classes[i]] == 'car':\n",
        "        x1, y1, x2, y2 = box\n",
        "        cv2.rectangle(output_image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
        "        label = f'{COCO_INSTANCE_CATEGORY_NAMES[filtered_classes[i]]}: {pred_scores[i]:.2f}'\n",
        "        cv2.putText(output_image, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "\n",
        "# Display the image\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(output_image)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Optionally save the output image\n",
        "output_image_path = '/content/drive/MyDrive/Colab Notebooks/Dataset/output_car_image.jpg'\n",
        "cv2.imwrite(output_image_path, cv2.cvtColor(output_image, cv2.COLOR_RGB2BGR))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load a pre-trained Faster R-CNN model\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Define COCO class names (first class is the background)\n",
        "COCO_INSTANCE_CATEGORY_NAMES = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter',\n",
        "    'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra',\n",
        "    'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis',\n",
        "    'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "    'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon',\n",
        "    'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet',\n",
        "    'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
        "    'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
        "    'toothbrush'\n",
        "]\n",
        "\n",
        "# Define the image transformation\n",
        "transform = T.Compose([\n",
        "    T.ToTensor()\n",
        "])\n",
        "\n",
        "# Load the image\n",
        "image_path = '/content/drive/MyDrive/Colab Notebooks/Dataset/Images/Classification.jpg'\n",
        "image = Image.open(image_path)\n",
        "image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    predictions = model(image_tensor)\n",
        "\n",
        "# Get the predictions\n",
        "pred_boxes = predictions[0]['boxes'].cpu().numpy()\n",
        "pred_scores = predictions[0]['scores'].cpu().numpy()\n",
        "pred_classes = predictions[0]['labels'].cpu().numpy()\n",
        "\n",
        "# Filter out low confidence scores\n",
        "threshold = 0.94\n",
        "filtered_boxes = pred_boxes[(pred_scores >= threshold) & (pred_classes == COCO_INSTANCE_CATEGORY_NAMES.index('car'))]\n",
        "filtered_scores = pred_scores[(pred_scores >= threshold) & (pred_classes == COCO_INSTANCE_CATEGORY_NAMES.index('car'))]\n",
        "filtered_classes = pred_classes[(pred_scores >= threshold) & (pred_classes == COCO_INSTANCE_CATEGORY_NAMES.index('car'))]\n",
        "\n",
        "# Draw bounding boxes on the original image\n",
        "output_image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "for i, box in enumerate(filtered_boxes):\n",
        "    x1, y1, x2, y2 = box\n",
        "    cv2.rectangle(output_image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
        "    label = f'{COCO_INSTANCE_CATEGORY_NAMES[filtered_classes[i]]}: {filtered_scores[i]:.2f}'\n",
        "    cv2.putText(output_image, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "\n",
        "# Display the image\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(output_image)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Optionally save the output image\n",
        "output_image_path = '/content/drive/MyDrive/Colab Notebooks/Dataset/output_car_image.jpg'\n",
        "cv2.imwrite(output_image_path, cv2.cvtColor(output_image, cv2.COLOR_RGB2BGR))\n"
      ],
      "metadata": {
        "id": "kD7kftYYsFCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the image with bounding boxes\n",
        "image_path = '/content/drive/MyDrive/Colab Notebooks/Dataset/download (37).png'\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Create a mask where the green lines are located\n",
        "lower_green = np.array([0, 255, 0], dtype=np.uint8)\n",
        "upper_green = np.array([0, 255, 0], dtype=np.uint8)\n",
        "mask = cv2.inRange(image, lower_green, upper_green)\n",
        "\n",
        "# Dilate the mask to cover the text and bounding box\n",
        "kernel = np.ones((3, 3), np.uint8)\n",
        "mask = cv2.dilate(mask, kernel, iterations=1)\n",
        "\n",
        "# Inpaint the image using the mask\n",
        "inpainted_image = cv2.inpaint(image, mask, 3, cv2.INPAINT_TELEA)\n",
        "\n",
        "# Convert the image from BGR to RGB\n",
        "output_image = cv2.cvtColor(inpainted_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the image\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(output_image)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Optionally save the output image\n",
        "output_image_path = '/mnt/data/output_image_without_boxes.png'\n",
        "cv2.imwrite(output_image_path, cv2.cvtColor(output_image, cv2.COLOR_RGB2BGR))\n"
      ],
      "metadata": {
        "id": "QstOB6R72ivy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iccnebtd3e6x"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}